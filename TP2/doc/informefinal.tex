\documentclass[a4paper,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{t1enc}

\usepackage[utf8]{inputenc}
\usepackage{t1enc}
\usepackage[spanish]{babel}
\usepackage[pdftex,usenames,dvipsnames]{color}
\usepackage[pdftex]{graphicx}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[table]{xcolor}
\usepackage[small,bf]{caption}
\usepackage{float}
\usepackage{subfig}
\usepackage{listings}
\usepackage{bm}
\usepackage{times}
\usepackage{marvosym}


\begin{document}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

\renewcommand{\lstlistingname}{C\'odigo Fuente}
\lstloadlanguages{Octave} 
\lstdefinelanguage{MyOctave}[]{Octave}{
        deletekeywords={beta,det},
        morekeywords={repmat}
} 
\lstset{
        language=MyOctave,
        stringstyle=\ttfamily,
        showstringspaces = false,
        basicstyle=\footnotesize\ttfamily,
        commentstyle=\color{gray},
        keywordstyle=\bfseries,
        numbers=left,
        numberstyle=\ttfamily\footnotesize,
        stepnumber=1,                   
        framexleftmargin=0.20cm,
        numbersep=0.37cm,              
        backgroundcolor=\color{white},
        showspaces=false,
        showtabs=false,
        frame=l,
        tabsize=4,
        captionpos=b,               
        breaklines=true,             
        breakatwhitespace=false,      
        mathescape=true
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% begin TITLE PAGE %%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{titlepage}
        \vfill
        \thispagestyle{empty}
        \begin{center}
                \includegraphics{./images/itba_logo.png}
                \vfill
                \Huge{Sistemas de Inteligencia Artificial}\\
                \vspace{1cm}
                \Huge{Redes Neuronales}\\
                \vspace{1cm}
                \Huge{Trabajo Pr\'actico Especial 2}\\
        \end{center}
        \vfill
        \large{
        \begin{tabular}{lcr}
                Civile, Juan Pablo && 50453\\
                Ordano, Esteban && 50753\\
                Crespo, Alvaro && 50758 \\
        \end{tabular}
}
        \vspace{2cm}
        \begin{center}
                \large{24 de abril de 2013}\\
        \end{center}
\end{titlepage}
\newpage

\setcounter{page}{1}

% \tableofcontents
% \newpage

\section{Definición del problema}

El problema consiste en la implementación de una red neuronal multicapa con aprendizaje supervisado que realice la predicción de series temporales. Para ello se supone que $x(t)$ (el valor de la 
serie en el paso temporal $t$) es alguna función desconocida de los valores de la serie en pasos anteriores, es decir, $x(t) = f (x(t - 1), x(t - 2), x(t - 3), \dots)$. 
La red neuronal deberá poder aproximar a la función $f$ desconocida. A priori no se conoce cuantos pasos temporales previos hay que considerar como argumento 
de la función $f$. Se utilizaron siempre menos de cuatro.

\section{Implementación}

    Se implementó una red multicapa del tipo \texttt{Feed Forward}, usando el algoritmo \texttt{Back Propagation} para el entrenamiento. La distribución inicial de pesos 
    se generó de manera aleatoria con valores acotados a un intervalo dependiente de la función de activación en uso. Como medida del error se usó la función de error cuadrático.

    \subsection{Funciones de activación}
    Se utilizaron las siguientes funciones de activación, y sus respectivas derivadas:

    \begin{itemize}
        \item Función Sigmoidea
            \[ g(x) = \dfrac{1}{1 + exp^{-x}} \]
            \[ g'(x) = \dfrac{1}{(-2 * cosh(x) - 2)}\]
        \item Tangente hiperbólica
            \[ g(x) = tanh(x) \]
            \[ g'(x) = sech(x)^{2} \]
    \end{itemize}

    \subsection{Normalización de la entrada y la salida}

        Dado que las entradas y salidades de la red pertenecen al intervalo $(-4, 4)$, y las entradas y las salidas de las funciones de activación utilizadas 
        pertenecen al intervalo $(0,1)$ para el caso de la sigmoidea, y al $(-1,1)$ en el caso de la tangente hiperbólica, se debe realizar una normalización 
        tanto en la entrada como en la salida de la red. Estas normalizaciones son las siguentes:

        \begin{itemize}
            \item Sigmoidea
                Para la entrada: \[ \xi_{i} = \frac{x_{i} + 4}{8} \]
                Para la salida: \[ o_{i} = x_{i} * 4 \]
            \item Tangente hiperbólica
                Para la entrada: \[ \xi_{i} = x / 4 \]
                Para la salida: \[ o_{i} = (x - 0.5) * 8 \]
        \end{itemize}

        Se puede ver fácilmente que la función para normalizar una entrada es la inversa de la función que normaliza la salida.

    \subsection{Disminución de la cantidad de entrenamientos descartados}

        %TODO: Esto no deberia ir despues de las mejoras? O al menos despues de mencionar eta adaptativo?
        \label{less_rollbacks}
        Se consideró incorporar otros criterios para deshacer entrenamientos utilizando la estrategia de entrenamiento adaptativo. Además de considerar el error cuadrático medio, 
        se consideró como un valor relevante el de un percentil alto (se seleccionó el percentil $90$) de los errores del conjunto de entrenamiento. El objetivo es no descartar 
        entrenamientos que son mejores, aunque el error medio no disminuya. Dos nuevos criterios utilizando este nuevo parámetro son:

        \begin{itemize}
            \item Se hace rollback si disminuye el error cuadrático medio \textbf{y} disminuye el percentil 90.
            \item Se hace rollback si disminuye el error cuadrático medio \textbf{o} disminuye el percentil 90.
        \end{itemize}

    \subsection{Selección de los parámetros de configuración}

        \label{sec:configuracion}
        El entrenamiento de la red neuronal con las estrategias implementadas tiene una extensa variedad de parámetros de configuración. Además de $\eta$, 
        el coeficiente de aprendizaje, el entrenamiento con la estrategia \textit{Momentum} requiere seleccionar un valor para $\alpha$, el término que pesa el descenso promedio. 
        La estrategia de entrenamiento adaptativo requiere la selección de más parámetros: los factores $a$, $b$, y la cantidad de pasos $k$.
        Se determinaron valores iniciales que producían resultados suficientemente satisfactorios en 1500 iteraciones . Se consideró cada parámetro independientemente de 
        los demás y se iteró por valores relevantes para cada variable.

    \subsection{Mejoras}

        \subsubsection{Momentum}

        Momentum considera los valores de $\delta w_{ij}$ de pasos anteriores a la hora de actualizar los pesos del paso actual.
        En particular, se agrega al cambio dado por \texttt{Back Propagation}, el cambio de la iteración anterior pesado por un factor $\alpha$.

        \subsubsection{$\eta$ adaptativo}

        Esta mejora busca alterar el valor de $\eta$ de acuerdo al progreso del entrenamiento.
        Para esto se considera que si se encuentra una seguidilla de $k$ pasos que disminuyen el error, entonces se tiene un buen camino de entrenamiento y por lo tanto se aumenta 
        el valor en una constante $a$ para explotar este camino. Y si por el contrario nos encontramos en un mal camino, se disminuye el valor en un porcentaje $b$.
        Cuando se disminuye el valor, se desactiva temporalmente \texttt{Momentum} y se descarta el paso realizado.
        Una vez que se encuentra un paso que disminuye el error se reactiva \texttt{Momentum}.

        \subsubsection{Ruido}

        Se intentó introducir ruido a los pesos de la red entre pasos para evitar estancarse en mínimos locales.
        Se agregó a cada peso un valor aleatorio entre 0 y 1, adjustado por la cantidad de pasos que no disminuyeron el error, y una constante.
        Esta optimización fue descartada por que rápidamente se encontró que no producía resultados positivos.

    \subsection{Conjunto de entrenamiento y prueba}

    Se tiene un conjunto de 1000 puntos de la serie a ser generalizada.
    Para el entrenamiento de la red se usó los primeros 800 puntos, y los restantes 200 puntos se usaron como conjunto de prueba.

\section{Resultados}

    \subsection{Comparación de Funciones de Activación}
    \label{sec:comparacion-activacion}

    Para realizar una comparación entre las funciones de activación utilizadas, se definió un set de arquitecturas de prueba. Se mantuvieron fijos los parámetros de entrada de la red.
    Cabe destacar que, según la función de activación usada en cada caso, se debieron acotar los valores aleatorios de los pesos utilizados como entrada al algoritmo de aprendizaje
    supervisado. Como era de esperarse, para la función sigmoidea, hubo que generar números muy pequeños en módulo (cercanos a 0), para que no se saturen las conexiones, y se impida el aprendizaje.
    Para el caso de la tangente hiperbólica, en cambio, esos pesos  iniciales pequeños no retornaron resultados positivos, como si lo hicieron las pruebas realizadas con valores 
    aleatorios pero con cotas mayores.

     \begin{table}[H]
        \label{table-comparation-act-functions}

        \begin{center}
        \begin{tabular}{|l|r|r|}
            \hline
            Arquitectura \textbackslash Función de activación & Tangente hiperbólica & Sigmoidea \\
            \hline
            [2 5 4 1] & $0.023053$ & $0.31491$ \\
            \hline
            [3 10 6 1] & $0.053163$ & $0.30446$  \\
            \hline
            [2 10 6 1] & $0.029276$ & $0.31163$  \\
            \hline
            [2 4 2 1]  & $0.36896$ & $0.31504$  \\
            \hline
            [3 14 8 1] & $0.028585$ & $0.30841$  \\
            \hline
        \end{tabular}
        \end{center}
        \caption{Comparación del error cuadrático medio entre las funciones de activación \textit{Tangente hiperbólica} y \textit{Sigmoidea}.}

    \end{table}

    Se observa que las redes obtenidas con la funcion $tanh$ son ampliamente superiores a sus contrapartes con la funcion \textit{Sigmoidea}.
    A partir de este resultado, optamos por concentrar nuestra atencion en redes construidas con la funcion \textit{Tangente hiperbolica}.

    \subsection{Optimizacion de parametros}
    \label{sec:parametros-optimos}

        Se muestran los resultados obtenidos de la seleccion despcripta en la seccion \ref{sec:configuracion} para cada variable en la \ref{tabla_configuracion}. 
        Al respecto, se hacen las siguientes observaciones:

        \begin{itemize}
        \item El mejor valor para el coeficiente $alpha$ es de $0.3$, mucho menor que el sugerido $0.9$ de la cátedra.
        \item El mejor valor del parámetro $a$ es de $0.0001$. Este valor es menor de lo esperado, ya que en pruebas preliminares un valor de $0.01$ 
              no arrojaba peores resultados que correr el algoritmo sin la estrategia de entrenamiento adaptativo.
        \item El mejor valor del parámetro $b$ es de $0.01$. Esto es mayor de lo esperado, el valor que se utilizaba inicialmente era de 0.001.
        \end{itemize}

        \begin{table}
            \begin{tabular}{|c|c|c|c|c|}
                \hline
                Parámetro & Minimo valor & Incremento & Máximo valor & Mejor valor \\ \hline
                $alpha$ & $0.1$ & $+ 0.1$ & $0.9$ & $0.3$ \\ \hline
                $a$ & $0.00001$ & $\Cross 10$ & $0.01$ & $0.0001$ \\ \hline
                $b$ & $0.00001$ & $\Cross 10$ & $0.01$ & $0.01$ \\ \hline
                $k$ & $1$ & $+ 1$ & $5$ & $4$ \\ \hline
            \end{tabular}
            \caption{Parámetros de configuración de la red neuronal}
            \label{tabla_configuracion}
        \end{table}

        Con este analisis encontramos que los valores utilizados como parametros en la seccion \ref{sec:comparacion-activacion} resultaron muy cercanos a los optimos.
        El unico parametro con valor distinto es $a$ con un valro de $0.001$.

    \subsection{Optimizacion de arquitectura}
    \lable{sec:arquitectura-optima}

    % FILL ME IN

\section{Conclusiones}

% Resumir analisis
% Comparar las "mejores" redes, vease output_3, output_5, y magico de tebez. y decir por que nos parece mejor _3

% Dar una conclusión acerca de las funciones de activación.

\include{figures}

\end{document}
